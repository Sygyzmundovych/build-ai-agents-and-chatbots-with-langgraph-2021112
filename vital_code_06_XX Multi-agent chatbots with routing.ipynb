{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c7909b-b762-4844-a075-9874d62a17df",
   "metadata": {},
   "source": [
    "## Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f70936-4b41-4991-91ec-027962cd14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import AzureChatOpenAI\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "import os\n",
    "# Setup the LLM for the agent\n",
    "\n",
    "# Setup the LLM\n",
    "model = ChatOpenAI(proxy_model_name=\"gpt-4o-mini\")\n",
    "embedding = OpenAIEmbeddings(proxy_model_name=\"text-embedding-3-small\")\n",
    "\n",
    "# Test the model\n",
    "# response = model.invoke(\"Hello, what is the AI Agent? Give me a brief answer.\")\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9d506-3cbf-4bcd-a00f-d86a4c2aa4a7",
   "metadata": {},
   "source": [
    "## 06.03. Using agents as Graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f6f81-ec83-4229-88eb-63592d460bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reuse the agents created in the previous chapters by importing their notebooks\n",
    "#This will also import the chatbot and execute the code available.\n",
    "#Ignore / hide the code output and use only the agents\n",
    "\n",
    "#import the Product QnA Agent\n",
    "%run \"vital_code_03_XX Product QnA Agentic chatbot.ipynb\" \n",
    "print(\"===============================================================\")\n",
    "#import the orders agents\n",
    "%run \"vital_code_04_XX Orders Chatbot with custom agent.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc6a85-8f73-4c0c-bac0-c6f24badbf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "# Helper function to invoke an agent\n",
    "def agent_node(state, agent, name, config):\n",
    "\n",
    "    #extract thread-id from request for conversation memory\n",
    "    thread_id=config[\"metadata\"][\"thread_id\"]\n",
    "    #Set the config for calling the agent\n",
    "    agent_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    #Pass the thread-id to establish memory for chatbot\n",
    "    #Invoke the agent with the state\n",
    "    result = agent.invoke(state, agent_config)\n",
    "\n",
    "    # Convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        final_result=AIMessage(result['messages'][-1].content)\n",
    "    return {\n",
    "        \"messages\": [final_result]\n",
    "    }\n",
    "\n",
    "#Create the product QnA node\n",
    "product_QnA_node=functools.partial(agent_node, \n",
    "                                   agent=product_QnA_agent, \n",
    "                                   name=\"Product_QnA_Agent\")\n",
    "#Create the Orders node\n",
    "#For a custom agent, the agent graph need to be provided as input\n",
    "orders_node=functools.partial(agent_node,\n",
    "                              agent=orders_agent.agent_graph,\n",
    "                              name=\"Orders_Agent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d925a9-4050-4de2-8dcb-bd9c044470fb",
   "metadata": {},
   "source": [
    "## 06.04. Create the Routing Agent & Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31b5b9-649d-4b6f-9480-b7754618eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the routing agent\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "import operator\n",
    "\n",
    "class RouterAgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "class RouterAgent:\n",
    "\n",
    "    def __init__(self, model, system_prompt, smalltalk_prompt, debug=False):\n",
    "        \n",
    "        self.system_prompt=system_prompt\n",
    "        self.smalltalk_prompt=smalltalk_prompt\n",
    "        self.model=model\n",
    "        self.debug=debug\n",
    "        \n",
    "        router_graph=StateGraph(RouterAgentState)\n",
    "        router_graph.add_node(\"Router\",self.call_llm)\n",
    "        router_graph.add_node(\"Product_Agent\",product_QnA_node)\n",
    "        router_graph.add_node(\"Orders_Agent\",orders_node)\n",
    "        router_graph.add_node(\"Small_Talk\", self.respond_smalltalk)\n",
    "                              \n",
    "        router_graph.add_conditional_edges(\n",
    "            \"Router\",\n",
    "            self.find_route,\n",
    "            {\"PRODUCT\": \"Product_Agent\", \n",
    "             \"ORDER\" : \"Orders_Agent\",\n",
    "             \"SMALLTALK\" : \"Small_Talk\",\n",
    "             \"END\": END }\n",
    "        )\n",
    "\n",
    "        #One way routing, not coming back to router\n",
    "        router_graph.add_edge(\"Product_Agent\",END)\n",
    "        router_graph.add_edge(\"Orders_Agent\",END)\n",
    "        router_graph.add_edge(\"Small_Talk\",END)\n",
    "        \n",
    "        #Set where there graph starts\n",
    "        router_graph.set_entry_point(\"Router\")\n",
    "        self.router_graph = router_graph.compile()\n",
    "\n",
    "    def call_llm(self, state:RouterAgentState):\n",
    "        messages=state[\"messages\"]\n",
    "        if self.debug:\n",
    "            print(f\"Call LLM received {messages}\")\n",
    "            \n",
    "        #If system prompt exists, add to messages in the front\n",
    "        if self.system_prompt:\n",
    "            messages = [SystemMessage(content=self.system_prompt)] + messages\n",
    "\n",
    "        #invoke the model with the message history\n",
    "        result = self.model.invoke(messages)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Call LLM result {result}\")\n",
    "        return { \"messages\":[result] }\n",
    "\n",
    "    def respond_smalltalk(self, state:RouterAgentState):\n",
    "        messages=state[\"messages\"]\n",
    "        if self.debug:\n",
    "            print(f\"Small talk received: {messages}\")\n",
    "            \n",
    "        #If system prompt exists, add to messages in the front\n",
    "        \n",
    "        messages = [SystemMessage(content=self.smalltalk_prompt)] + messages\n",
    "\n",
    "        #invoke the model with the message history\n",
    "        result = self.model.invoke(messages)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Small talk result {result}\")\n",
    "        return { \"messages\":[result] }\n",
    "        \n",
    "    def find_route(self, state:RouterAgentState):\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if self.debug: \n",
    "            print(\"Router: Last result from LLM : \", last_message)\n",
    "\n",
    "        #Set the last message as the destination\n",
    "        destination=last_message.content\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Destination chosen : {destination}\")\n",
    "        return destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9af521-affc-463d-927a-d0e09426f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the chatbot\n",
    "from IPython.display import Image\n",
    "\n",
    "#Setup the system problem\n",
    "system_prompt = \"\"\" \n",
    "You are a Router, that analyzes the input query and chooses 4 options:\n",
    "SMALLTALK: If the user input is small talk, like greetings and good byes.\n",
    "PRODUCT: If the query is a product question about laptops, like features, specifications and pricing.\n",
    "ORDER: If the query is about orders for laptops, like order status, order details or update order quantity\n",
    "END: Default, when its neither PRODUCT or ORDER.\n",
    "\n",
    "The output should only be just one word out of the possible 4 : SMALLTALK, PRODUCT, ORDER, END.\n",
    "\"\"\"\n",
    "\n",
    "smalltalk_prompt=\"\"\"\n",
    "If the user request is small talk, like greetings and goodbyes, respond professionally.\n",
    "Mention that you will be able to answer questions about laptop product features and provide order status and updates.\n",
    "\"\"\"\n",
    "\n",
    "router_agent = RouterAgent(model, \n",
    "                           system_prompt, \n",
    "                           smalltalk_prompt,\n",
    "                           debug=False)\n",
    "\n",
    "Image(router_agent.router_graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8e58e-67eb-4bb0-ae26-d904290e59eb",
   "metadata": {},
   "source": [
    "## 06.05 Execute the Routing chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ad40f-912d-4e63-bd00-d2a017e9dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute a single request\n",
    "messages=[HumanMessage(content=\"Tell me about the features of SpectraBook\")]\n",
    "result=router_agent.router_graph.invoke({\"messages\":messages},config)\n",
    "for message in result['messages']:\n",
    "    print(message.pretty_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1937615-0441-4ab8-8dae-46d39de88fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute a single request\n",
    "messages=[HumanMessage(content=\"What is the status of order ORD-7311?\")]\n",
    "result=router_agent.router_graph.invoke({\"messages\":messages},config)\n",
    "for message in result['messages']:\n",
    "    print(message.pretty_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de2bf5-a850-46c7-b638-5737f4aefb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "#Send a sequence of messages to chatbot and get its response\n",
    "#This simulates the conversation between the user and the Agentic chatbot\n",
    "user_inputs = [\n",
    "    \"How are you doing?\",\n",
    "    \"Please show me the details of the order ORD-7311\",\n",
    "    \"Can you add one more of that laptop to the order? \",\n",
    "    \"Tell me about the features of SpectraBook laptop\",\n",
    "    \"How much does it cost?\",\n",
    "    \"Bye\"\n",
    "]\n",
    "\n",
    "#Create a new thread\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "for input in user_inputs:\n",
    "    print(f\"----------------------------------------\\nUSER : {input}\")\n",
    "    #Format the user message\n",
    "    user_message = {\"messages\":[HumanMessage(input)]}\n",
    "    #Get response from the agent\n",
    "    ai_response = router_agent.router_graph.invoke(user_message,config=config)\n",
    "    #Print the response\n",
    "    print(f\"\\nAGENT : {ai_response['messages'][-1].content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
